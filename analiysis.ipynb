{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Creation and Cleansing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-14 15:58:04.243979: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "DEBUG:tensorflow:Falling back to TensorFlow client; we recommended you install the Cloud TPU client directly with pip install cloud-tpu-client.\n",
      "DEBUG:h5py._conv:Creating converter from 7 to 5\n",
      "DEBUG:h5py._conv:Creating converter from 5 to 7\n",
      "DEBUG:h5py._conv:Creating converter from 7 to 5\n",
      "DEBUG:h5py._conv:Creating converter from 5 to 7\n",
      "DEBUG:src.llm_dataset_filler:Total rows with missing values: 14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Full Merged Dataset:\n",
      "   id   Age  Gender Education Level          Job Title  Years of Experience  \\\n",
      "0   0  32.0    Male      Bachelor's  Software Engineer                  5.0   \n",
      "1   1  28.0  Female        Master's       Data Analyst                  3.0   \n",
      "2   2  45.0    Male             PhD     Senior Manager                 15.0   \n",
      "3   3  36.0  Female      Bachelor's    Sales Associate                  7.0   \n",
      "4   4  52.0    Male        Master's           Director                 20.0   \n",
      "\n",
      "                                         Description    Salary  \n",
      "0  I am a 32-year-old male working as a Software ...   90000.0  \n",
      "1  I am a 28-year-old data analyst with a Master'...   65000.0  \n",
      "2  I am a 45-year-old Senior Manager with a PhD a...  150000.0  \n",
      "3  I am a 36-year-old female Sales Associate with...   60000.0  \n",
      "4  I am a 52-year-old male with over two decades ...  200000.0  \n",
      "      id   Age  Gender Education Level                      Job Title  \\\n",
      "370  370  35.0  Female      Bachelor's       Senior Marketing Analyst   \n",
      "371  371  43.0    Male        Master's         Director of Operations   \n",
      "372  372  29.0  Female      Bachelor's         Junior Project Manager   \n",
      "373  373  34.0    Male      Bachelor's  Senior Operations Coordinator   \n",
      "374  374  44.0  Female             PhD        Senior Business Analyst   \n",
      "\n",
      "     Years of Experience                                        Description  \\\n",
      "370                  8.0  As a 35-year-old Senior Marketing Analyst with...   \n",
      "371                 19.0  I am a 43-year-old male with a Master's degree...   \n",
      "372                  2.0  As a 29-year-old female Junior Project Manager...   \n",
      "373                  7.0  As a Senior Operations Coordinator with a Bach...   \n",
      "374                 15.0  I am a 44-year-old Senior Business Analyst wit...   \n",
      "\n",
      "       Salary  \n",
      "370   85000.0  \n",
      "371  170000.0  \n",
      "372   40000.0  \n",
      "373   90000.0  \n",
      "374  150000.0  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 375 entries, 0 to 374\n",
      "Data columns (total 8 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   id                   375 non-null    int64  \n",
      " 1   Age                  370 non-null    float64\n",
      " 2   Gender               370 non-null    object \n",
      " 3   Education Level      370 non-null    object \n",
      " 4   Job Title            370 non-null    object \n",
      " 5   Years of Experience  373 non-null    float64\n",
      " 6   Description          372 non-null    object \n",
      " 7   Salary               373 non-null    float64\n",
      "dtypes: float64(3), int64(1), object(4)\n",
      "memory usage: 23.6+ KB\n",
      "None\n",
      "\n",
      "Missing Values in Full Dataset:\n",
      "id                     0\n",
      "Age                    5\n",
      "Gender                 5\n",
      "Education Level        5\n",
      "Job Title              5\n",
      "Years of Experience    2\n",
      "Description            3\n",
      "Salary                 2\n",
      "dtype: int64\n",
      "\n",
      "Rows with Missing Values:\n",
      "      id   Age  Gender Education Level                         Job Title  \\\n",
      "51    51  33.0    Male        Master's                               NaN   \n",
      "60    60  51.0  Female        Master's                               NaN   \n",
      "111  111  37.0    Male      Bachelor's          Software Project Manager   \n",
      "125  125  26.0    Male      Bachelor's                 Junior Accountant   \n",
      "139  139  43.0  Female             NaN  Senior Product Marketing Manager   \n",
      "172  172   NaN     NaN             NaN                               NaN   \n",
      "177  177  31.0    Male      Bachelor's                 Junior Accountant   \n",
      "219  219  40.0     NaN      Bachelor's       Senior Sales Representative   \n",
      "221  221   NaN  Female      Bachelor's    Junior Social Media Specialist   \n",
      "225  225  40.0     NaN      Bachelor's          Senior Marketing Manager   \n",
      "235  235  32.0     NaN      Bachelor's       Junior Sales Representative   \n",
      "260  260   NaN     NaN             NaN                               NaN   \n",
      "261  261  37.0  Female             NaN          Senior Financial Manager   \n",
      "287  287   NaN  Female      Bachelor's          Senior Marketing Analyst   \n",
      "315  315   NaN    Male      Bachelor's          Senior Software Engineer   \n",
      "332  332  45.0  Female             PhD                               NaN   \n",
      "366  366  31.0  Female             NaN          Junior Financial Analyst   \n",
      "\n",
      "     Years of Experience                                        Description  \\\n",
      "51                   7.0  I am a 33-year-old Business Intelligence Analy...   \n",
      "60                  23.0  I am a 51-year-old female with a Master's degr...   \n",
      "111                  9.0                                                NaN   \n",
      "125                  2.0                                                NaN   \n",
      "139                 14.0  I am a 43-year-old Senior Product Marketing Ma...   \n",
      "172                  NaN  As an employee, I bring a wealth of diverse ex...   \n",
      "177                  4.0                                                NaN   \n",
      "219                 12.0  I am a 40-year-old Senior Sales Representative...   \n",
      "221                  3.0  I am a 31-year-old female currently working as...   \n",
      "225                 11.0  I am a 40-year-old Senior Marketing Manager wi...   \n",
      "235                  3.0  As a 32-year-old Junior Sales Representative w...   \n",
      "260                  NaN  As an employee, I bring a unique blend of skil...   \n",
      "261                 10.0  I am a 37-year-old Senior Financial Manager wi...   \n",
      "287                  8.0  As a 35-year-old Senior Marketing Analyst with...   \n",
      "315                 13.0  I am a Senior Software Engineer with 13 years ...   \n",
      "332                 16.0  I am a 45-year-old Senior UX Designer with a P...   \n",
      "366                  3.0  I am a 31-year-old female working as a Junior ...   \n",
      "\n",
      "       Salary  \n",
      "51    85000.0  \n",
      "60   170000.0  \n",
      "111   95000.0  \n",
      "125   40000.0  \n",
      "139  120000.0  \n",
      "172       NaN  \n",
      "177   50000.0  \n",
      "219  100000.0  \n",
      "221   45000.0  \n",
      "225  105000.0  \n",
      "235   45000.0  \n",
      "260       NaN  \n",
      "261  120000.0  \n",
      "287   85000.0  \n",
      "315  130000.0  \n",
      "332  160000.0  \n",
      "366   50000.0  \n"
     ]
    },
    {
     "ename": "CancelledError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCancelledError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m full_dataset \u001b[38;5;241m=\u001b[39m data_loading\u001b[38;5;241m.\u001b[39mload_data(data_files)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m#preprocessing of the dataframe adds missing values with LLM inference over descriptions of each row, drops the incomplete rows and cleans up the data.\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m cleansed_dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m preprocessing\u001b[38;5;241m.\u001b[39mpreprocess(full_dataset)\n\u001b[1;32m     26\u001b[0m visualize_data\u001b[38;5;241m.\u001b[39mvisualize_dataset(cleansed_dataset)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m#split the dataset into an 80 / 20 ratio for training and testing.\u001b[39;00m\n",
      "File \u001b[0;32m~/Predictive_Models/salary_predictive_model/src/preprocessing.py:42\u001b[0m, in \u001b[0;36mpreprocess\u001b[0;34m(full_dataset)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(missing_rows)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m#use an LLM to infer missing values form description column.\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m full_dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m llm_dataset_filler\u001b[38;5;241m.\u001b[39minfer_missing_values_in_dataframe(full_dataset)\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mMissing Values in Full Dataset:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m#print Rows that cant be infered and cleanse them\u001b[39;00m\n",
      "File \u001b[0;32m~/Predictive_Models/salary_predictive_model/src/llm_dataset_filler.py:126\u001b[0m, in \u001b[0;36minfer_missing_values_in_dataframe\u001b[0;34m(df, fields_to_infer, description_field, base_url, model_name)\u001b[0m\n\u001b[1;32m    123\u001b[0m                 tasks\u001b[38;5;241m.\u001b[39mappend(task)\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;66;03m# Gather results concurrently\u001b[39;00m\n\u001b[0;32m--> 126\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mgather(\u001b[38;5;241m*\u001b[39mtasks)\n\u001b[1;32m    128\u001b[0m \u001b[38;5;66;03m# Update the DataFrame with inferred values\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, field, inferred_value \u001b[38;5;129;01min\u001b[39;00m results:\n",
      "File \u001b[0;32m~/Predictive_Models/salary_predictive_model/src/llm_dataset_filler.py:56\u001b[0m, in \u001b[0;36minfer_missing_value\u001b[0;34m(session, row, index, field, base_url, model_name)\u001b[0m\n\u001b[1;32m     53\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/api/generate\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 56\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m session\u001b[38;5;241m.\u001b[39mpost(url, json\u001b[38;5;241m=\u001b[39mpayload) \u001b[38;5;28;01mas\u001b[39;00m response:\n\u001b[1;32m     57\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[1;32m     58\u001b[0m             logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIndex \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mindex\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: Failed to infer \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfield\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. HTTP status code: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Predictive_Models/salary_predictive_model/.venv/lib/python3.12/site-packages/aiohttp/client.py:1425\u001b[0m, in \u001b[0;36m_BaseRequestContextManager.__aenter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1424\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__aenter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _RetType:\n\u001b[0;32m-> 1425\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resp: _RetType \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_coro\n\u001b[1;32m   1426\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resp\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__aenter__\u001b[39m()\n",
      "File \u001b[0;32m~/Predictive_Models/salary_predictive_model/.venv/lib/python3.12/site-packages/aiohttp/client.py:730\u001b[0m, in \u001b[0;36mClientSession._request\u001b[0;34m(self, method, str_or_url, params, data, json, cookies, headers, skip_auto_headers, auth, allow_redirects, max_redirects, compress, chunked, expect100, raise_for_status, read_until_eof, proxy, proxy_auth, timeout, verify_ssl, fingerprint, ssl_context, ssl, server_hostname, proxy_headers, trace_request_ctx, read_bufsize, auto_decompress, max_line_size, max_field_size)\u001b[0m\n\u001b[1;32m    728\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m req\u001b[38;5;241m.\u001b[39msend(conn)\n\u001b[1;32m    729\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 730\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mstart(conn)\n\u001b[1;32m    731\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:\n\u001b[1;32m    732\u001b[0m     resp\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/Predictive_Models/salary_predictive_model/.venv/lib/python3.12/site-packages/aiohttp/client_reqrep.py:1059\u001b[0m, in \u001b[0;36mClientResponse.start\u001b[0;34m(self, connection)\u001b[0m\n\u001b[1;32m   1057\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1058\u001b[0m     protocol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_protocol\n\u001b[0;32m-> 1059\u001b[0m     message, payload \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m protocol\u001b[38;5;241m.\u001b[39mread()  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[1;32m   1060\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m http\u001b[38;5;241m.\u001b[39mHttpProcessingError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m   1061\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ClientResponseError(\n\u001b[1;32m   1062\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_info,\n\u001b[1;32m   1063\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistory,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1066\u001b[0m         headers\u001b[38;5;241m=\u001b[39mexc\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m   1067\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mexc\u001b[39;00m\n",
      "File \u001b[0;32m~/Predictive_Models/salary_predictive_model/.venv/lib/python3.12/site-packages/aiohttp/streams.py:671\u001b[0m, in \u001b[0;36mDataQueue.read\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_waiter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loop\u001b[38;5;241m.\u001b[39mcreate_future()\n\u001b[1;32m    670\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 671\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_waiter\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (asyncio\u001b[38;5;241m.\u001b[39mCancelledError, asyncio\u001b[38;5;241m.\u001b[39mTimeoutError):\n\u001b[1;32m    673\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_waiter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mCancelledError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import matplotlib.font_manager as fm\n",
    "import logging\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "fm._log.setLevel(logging.WARNING)\n",
    "from src import data_loading\n",
    "from src import preprocessing\n",
    "from src import visualize_data\n",
    "from src import feature_engenieering\n",
    "from src import modeling\n",
    "from src import evaluation\n",
    "from src import model_compare\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#files path for the raw dataset:\n",
    "data_files = ['./data/people.csv','./data/descriptions.csv','./data/salary.csv',]\n",
    "\n",
    "#merge datasets in a cohesive Dataframe\n",
    "full_dataset = data_loading.load_data(data_files)\n",
    "\n",
    "#preprocessing of the dataframe adds missing values with LLM inference over descriptions of each row, drops the incomplete rows and cleans up the data.\n",
    "cleansed_dataset = await preprocessing.preprocess(full_dataset)\n",
    "\n",
    "visualize_data.visualize_dataset(cleansed_dataset)\n",
    "\n",
    "#split the dataset into an 80 / 20 ratio for training and testing.\n",
    "X_train, X_test, y_train, y_test = feature_engenieering.split_data(cleansed_dataset)\n",
    "\n",
    "\n",
    "#normalize and scale the datasets using MinMaxScaler and target encoder for random forest\n",
    "\n",
    "normalized_X_train, te, scaler = feature_engenieering.normalize_train_data(X_train, y_train,MinMaxScaler())\n",
    "\n",
    "normalized_X_test = feature_engenieering.normalize_test_data(X_test, te, scaler)\n",
    "\n",
    "\n",
    "\n",
    "#normalize and scale the datasets using MinMaxScaler and target encoder for Neural Networks\n",
    "\n",
    "normalized_X_train_nn, te_nn, scaler_nn = feature_engenieering.normalize_train_data(X_train, y_train,StandardScaler(),\"nn_\")\n",
    "\n",
    "normalized_X_test_nn = feature_engenieering.normalize_test_data(X_test, te_nn, scaler_nn)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy Regressor Baseline model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the datasets created we use the train with MinMaxScaling dataset splits in a script to create a Random Forest Regressor using the scikit-learn framework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We traing a Dummy Reggressor to use as a baseline for model performance comparison and then train a Random Forest Regressor algorithm with hyperparameter tuning. We also evaluate the trained model by calculating metrics such as mean absolute error (MAE), root mean squared error (RMSE) and R-squared e (R2) and plot a scatterplot of predicted vs actual salaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy = modeling.train_dummy_regressor(normalized_X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Regressor training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train a model using a random forest regressor algorithm and print out the predictions for the normalized test data.\n",
    "\n",
    "\n",
    "rf_model = modeling.train_model(normalized_X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use the test dataset to predict salaries based on the trained model for a first fast evaluation.\n",
    "\n",
    "evaluation.evaluate_model(normalized_X_test, y_test, normalized_X_train,y_train, rf_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we use Confidence intervals to further test the  models performance using bootstraping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation.calculate_metrics(normalized_X_test, y_test, rf_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest feature selection process.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I choose the Random Forest Reggresor to be able to catch non linear relationships better with realtively low data quantity for training, the model is Hyperparametrized using a grid approach and the best model is selected for testing.\n",
    "\n",
    "In the process of selecting features for the Random Forest Regressor model, based on correlation and feature importance analysis after the first \"naive\" model was trained in the normalized data as is to gather more information on the relationships and model error R-squared Score (R²).\n",
    "\n",
    "it is also quite notable that the heteroscedasticity present in the middle of the distribution seems to be caused by the dataset itself, most possibly by the lack of examples to fill the distribution appropiately, otherwise the distribution of residuals seems to be acceptable considering there are no statiscally significant outliers in the dataset.\n",
    "\n",
    "        Random Forest Regressor Performance After Hyperparameter Tuning:\n",
    "        Mean Squared Error (MSE): 866064920.96\n",
    "        Mean Absolute Error (MAE): 17982.33\n",
    "        R-squared Score (R²): 0.65\n",
    "        \n",
    "![img](./plots/residuals_distribution.png)\n",
    "![Feature Importance](./plots/feature_importance.png)\n",
    "![feature correlation heatmap](./plots/feature_correlation_heatmap.png)\n",
    "\n",
    "\n",
    "\n",
    "It can be seen now better results by droping geneder since it has a really low correlation with salary and importance , and lower the smoothing for the encoded job titles to 3 (10 was the previous value).\n",
    "\n",
    "        Random Forest Regressor Performance After Hyperparameter Tuning:\n",
    "        Mean Squared Error (MSE): 600148032.12\n",
    "        Mean Absolute Error (MAE): 14748.68\n",
    "        R-squared Score (R²): 0.76\n",
    "\n",
    "![img](./plots/residuals_distribution_2.png)\n",
    "![Feature Importance](./plots/feature_importance_2.png)\n",
    "![feature correlation heatmap](./plots/feature_correlation_heatmap_2.png)\n",
    "\n",
    "        \n",
    "next feature to remove, surprinsingly is education level wich has a low correlation with salary, but if pruned from the dataset the model shows performs worst than before with the same hyperparametrization.\n",
    "\n",
    "        Random Forest Regressor Performance After Hyperparameter Tuning:\n",
    "        Mean Squared Error (MSE): 808374516.33\n",
    "        Mean Absolute Error (MAE): 17240.95\n",
    "        R-squared Score (R²): 0.67\n",
    "\n",
    "![img](./plots/residuals_distribution_3.png)\n",
    "![Feature Importance](./plots/feature_importance_3.png)\n",
    "![feature correlation heatmap](./plots/feature_correlation_heatmap_3.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network training and evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in this step we create a second model to test performance of different approaches in this specific problem. I'm using the same dataset and features as the random forest regressor but normalized using the stardad scaling between -1 and 1 wich provides better performances on NN sequiential models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model = modeling.train_NN_model(normalized_X_train_nn,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use the test dataset to predict salaries based on the trained model for a first fast evaluation.\n",
    "\n",
    "evaluation.evaluate_NN_model(normalized_X_test_nn, y_test, nn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation.calculate_metrics(normalized_X_test_nn, y_test, nn_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_data = {\n",
    "    'Random Forest': (rf_model, normalized_X_test, y_test),\n",
    "    'Neural Network': (nn_model, normalized_X_test_nn, y_test),\n",
    "    'Dummy Regresson': (dummy, normalized_X_test, y_test)\n",
    "}\n",
    "\n",
    "comparison_results = model_compare.compare_models(models_data, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
